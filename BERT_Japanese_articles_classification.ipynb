{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT - Japanese articles classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYEwriN13dfp"
      },
      "source": [
        "BERTによる日本語文章分類\n",
        "\n",
        "You can follow my Japnese NLP story [HERE!](https://medium.com/@nithikorn.lert/japanese-nlp-using-bert-part-1-tokenization-bert%E3%81%A7%E6%97%A5%E6%9C%AC%E8%AA%9E%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E3%83%BC%E3%83%91%E3%83%BC%E3%83%881-%E3%83%88%E3%83%BC%E3%82%AF%E3%83%B3%E5%8C%96-167e7aa04a3b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXf9PZy6-gp4"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install fugashi\n",
        "!pip install ipadic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj1yFc8i-o2U"
      },
      "source": [
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertJapaneseTokenizer, BertForSequenceClassification\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276,
          "referenced_widgets": [
            "db63253986a04d56b2fbddf25b64b806",
            "703e5c4e26074f4d9ecdf74f38a7699a",
            "da48ff33727e4b46a92db245257a6ee9",
            "ada43876a1a14c3ab3f90bec9a673cce",
            "bfad51e9550443d2a2d1a8c8083bece8",
            "06c88b7bc9ff4862b8ca9355b0af887b",
            "2395e633cd674b48845df7ade9ee6e47",
            "2a00bdffee5f49f99f4612cbbe6629b5",
            "1212f9cf2fde4468857ae1cf78685f94",
            "976ef2fa06d847e58be1ee1e6974ffe4",
            "54a1636752b949608ed2e179f45a7ffb",
            "d0ca841d2946421da63f63b3ca49b7c6",
            "d95a2e4aa7934005be30e72d1bc5cd5f",
            "41389693d19e4d0fa8f51f988da33412",
            "a7979f60dad449aa8041f6e06b41b7b7",
            "bef546b998774dc3bda926d806173550",
            "d39b61051e9b41a0aef915ec01858cc3",
            "a34143a8ba474e84b231c9742efe73f4",
            "7433091688104d848788fda0776dba24",
            "9d8b8d1668ef46ffb5fd7427ced4697b",
            "1be46b8390ee4a078a9daf9562f53a61",
            "4c6e974283374e5aaf146fa4ad297708",
            "ac1cfdc84c1845ddaa7f7eccc8b5067d",
            "06df6cb7e3474764ad0ee919434d06e4",
            "22acdaf416dd464595d8628f2d57bd2b",
            "1ac09df57f764d16ae07847d21b07dc7",
            "715fdf33a64a49d1a07d8da1d8abc224",
            "26e6240ef0e54a4cbea6a882e9ca3ea2",
            "8d9a0a8dad6c42b68d09d8d0a1bf3889",
            "3df1a64e7cb643c1b6b31037e605f16f",
            "b41a9757073d4cc99321ebc13ddc0738",
            "4d66d468bab84e21a71eec5dbcf2ed43",
            "4acfa819b8e846cda3e6980188e6edd5",
            "ac48cd6ea29e46edaae0c86506effea1",
            "8dc646dce31e4f349901cb46bc126bc7",
            "b59a40fcb41149e9be144a1e0aa8c3a4",
            "bdf724d191ba463a9b56e7602b1353d3",
            "36f64760737d44b1a72e5c98af9ab5cd",
            "0baf12c43be74a50a6517a92e6736d92",
            "be7d35c3d8df4cd4a12d80454890cdef",
            "b0db751e846140abb7950bc6fd7a004c",
            "0c1864c138014a61bfa500a8e31a7830",
            "f40d95574c3149a0849470b908d9f430",
            "7921a55452054b27963dffbdfac4bcbd"
          ]
        },
        "id": "q8VTvCkn-wuz",
        "outputId": "f2b831a3-df99-4e82-8a36-8358dc784433"
      },
      "source": [
        "tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n",
        "bert_sc = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "bert_sc = bert_sc.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db63253986a04d56b2fbddf25b64b806",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/258k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0ca841d2946421da63f63b3ca49b7c6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/110 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac1cfdc84c1845ddaa7f7eccc8b5067d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/479 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac48cd6ea29e46edaae0c86506effea1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W20ZlYbw-0pA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19cb976-b14d-4d4e-a10a-202dde6e6f25"
      },
      "source": [
        "#データのダウンロード\n",
        "!wget https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
        "\n",
        "#ファイルの解凍\n",
        "!tar -zxf ldcc-20140209.tar.gz "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-31 05:12:20--  https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
            "Resolving www.rondhuit.com (www.rondhuit.com)... 59.106.19.174\n",
            "Connecting to www.rondhuit.com (www.rondhuit.com)|59.106.19.174|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8855190 (8.4M) [application/x-gzip]\n",
            "Saving to: ‘ldcc-20140209.tar.gz’\n",
            "\n",
            "ldcc-20140209.tar.g 100%[===================>]   8.44M  5.55MB/s    in 1.5s    \n",
            "\n",
            "2021-10-31 05:12:22 (5.55 MB/s) - ‘ldcc-20140209.tar.gz’ saved [8855190/8855190]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RS1wFTA_oDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac6f07f7-f421-4260-808f-ad5083263c99"
      },
      "source": [
        "category_list = os.listdir(\"/content/text/\")\n",
        "category_list "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CHANGES.txt',\n",
              " 'kaden-channel',\n",
              " 'peachy',\n",
              " 'it-life-hack',\n",
              " 'livedoor-homme',\n",
              " 'smax',\n",
              " 'sports-watch',\n",
              " 'dokujo-tsushin',\n",
              " 'movie-enter',\n",
              " 'topic-news',\n",
              " 'README.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAeeigtUAn5R"
      },
      "source": [
        "# トークナイザのロード\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOuo0qzEGOYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d01e008-c012-4a2f-a41e-75e78fe6cea6"
      },
      "source": [
        "# 例のファイルを見ようよ。\n",
        "ex_txt = open(\"/content/text/dokujo-tsushin/dokujo-tsushin-4778030.txt\").read().replace(\"\\u3000\", \"\").split(\"\\n\")\n",
        "ex_txt[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['http://news.livedoor.com/article/detail/4778030/',\n",
              " '2010-05-22T14:30:00+0900',\n",
              " '友人代表のスピーチ、独女はどうこなしている？',\n",
              " 'もうすぐジューン・ブライドと呼ばれる６月。独女の中には自分の式はまだなのに呼ばれてばかり……という「お祝い貧乏」状態の人も多いのではないだろうか？さらに出席回数を重ねていくと、こんなお願いごとをされることも少なくない。',\n",
              " '',\n",
              " '「お願いがあるんだけど……友人代表のスピーチ、やってくれないかな？」',\n",
              " '',\n",
              " 'さてそんなとき、独女はどう対応したらいいか？',\n",
              " '',\n",
              " '最近だとインターネット等で検索すれば友人代表スピーチ用の例文サイトがたくさん出てくるので、それらを参考にすれば、無難なものは誰でも作成できる。しかし由利さん（33歳）はネットを参考にして作成したものの「これで本当にいいのか不安でした。一人暮らしなので聞かせて感想をいってくれる人もいないし、かといって他の友人にわざわざ聞かせるのもどうかと思うし……」ということで活用したのが、なんとインターネットの悩み相談サイトに。そこに作成したスピーチ文を掲載し「これで大丈夫か添削してください」とメッセージを送ったというのである。']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MygfGl6eLgYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eca22bb-1388-4e10-e6a7-a8d291a7c21b"
      },
      "source": [
        " ex_txt[2:10] # なんとなく、最初の論文は関係のないテキストがあるืので、3行目から保ちます。PyhtonのListには0から始まるので注意ください。"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['友人代表のスピーチ、独女はどうこなしている？',\n",
              " 'もうすぐジューン・ブライドと呼ばれる６月。独女の中には自分の式はまだなのに呼ばれてばかり……という「お祝い貧乏」状態の人も多いのではないだろうか？さらに出席回数を重ねていくと、こんなお願いごとをされることも少なくない。',\n",
              " '',\n",
              " '「お願いがあるんだけど……友人代表のスピーチ、やってくれないかな？」',\n",
              " '',\n",
              " 'さてそんなとき、独女はどう対応したらいいか？',\n",
              " '',\n",
              " '最近だとインターネット等で検索すれば友人代表スピーチ用の例文サイトがたくさん出てくるので、それらを参考にすれば、無難なものは誰でも作成できる。しかし由利さん（33歳）はネットを参考にして作成したものの「これで本当にいいのか不安でした。一人暮らしなので聞かせて感想をいってくれる人もいないし、かといって他の友人にわざわざ聞かせるのもどうかと思うし……」ということで活用したのが、なんとインターネットの悩み相談サイトに。そこに作成したスピーチ文を掲載し「これで大丈夫か添削してください」とメッセージを送ったというのである。']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "0qE3dttEDSYz",
        "outputId": "db9180cb-c31e-48ee-ed97-4174eb926bb1"
      },
      "source": [
        "# BERTにはこう言うデータが好きです。\n",
        "\" \".join( ex_txt[2:10] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'友人代表のスピーチ、独女はどうこなしている？ もうすぐジューン・ブライドと呼ばれる６月。独女の中には自分の式はまだなのに呼ばれてばかり……という「お祝い貧乏」状態の人も多いのではないだろうか？さらに出席回数を重ねていくと、こんなお願いごとをされることも少なくない。  「お願いがあるんだけど……友人代表のスピーチ、やってくれないかな？」  さてそんなとき、独女はどう対応したらいいか？  最近だとインターネット等で検索すれば友人代表スピーチ用の例文サイトがたくさん出てくるので、それらを参考にすれば、無難なものは誰でも作成できる。しかし由利さん（33歳）はネットを参考にして作成したものの「これで本当にいいのか不安でした。一人暮らしなので聞かせて感想をいってくれる人もいないし、かといって他の友人にわざわざ聞かせるのもどうかと思うし……」ということで活用したのが、なんとインターネットの悩み相談サイトに。そこに作成したスピーチ文を掲載し「これで大丈夫か添削してください」とメッセージを送ったというのである。'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DMvI_79Th8h",
        "outputId": "ccc190ff-52f0-4ab7-a0f8-407522525e10"
      },
      "source": [
        "category_lst = [folder for folder in os.listdir('/content/text/') if not folder.endswith(\".txt\")]\n",
        "category_lst"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kaden-channel',\n",
              " 'peachy',\n",
              " 'it-life-hack',\n",
              " 'livedoor-homme',\n",
              " 'smax',\n",
              " 'sports-watch',\n",
              " 'dokujo-tsushin',\n",
              " 'movie-enter',\n",
              " 'topic-news']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXndAjQvmhNr",
        "outputId": "7c69a8ea-ded5-439d-e182-b2f7f4818280"
      },
      "source": [
        "all_content = []\n",
        "for label, folder_name in enumerate(category_lst):\n",
        "    directory = '/content/text/' + folder_name + \"/\"\n",
        "    print(directory)\n",
        "    for filename in os.listdir(directory):\n",
        "        txt = open(directory + filename).read().replace(\"\\u3000\", \"\").splitlines()[2:]\n",
        "        all_content.append(txt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text/kaden-channel/\n",
            "/content/text/peachy/\n",
            "/content/text/it-life-hack/\n",
            "/content/text/livedoor-homme/\n",
            "/content/text/smax/\n",
            "/content/text/sports-watch/\n",
            "/content/text/dokujo-tsushin/\n",
            "/content/text/movie-enter/\n",
            "/content/text/topic-news/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsmfIx92mhRM"
      },
      "source": [
        "count_lst = []\n",
        "seq_lst = [i for lst in all_content for i in lst]\n",
        "for seq in seq_lst:\n",
        "    count = len(seq)\n",
        "    if count != 0:\n",
        "        count_lst.append(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "cFl9nBBCp3I2",
        "outputId": "4e64c6e9-e600-4602-d1df-3833e1bf37a4"
      },
      "source": [
        "count_df = pd.Series(count_lst).value_counts().to_frame()\n",
        "count_df.columns = ['sentence_size']\n",
        "count_df.plot.hist(bins=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7441a4cd10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "cZqYVGapsU88",
        "outputId": "f30b8ac0-3b27-440f-de9c-973785350173"
      },
      "source": [
        "count_df.describe() # 4053 is too long and need time to train. So, in this example we choose 288 as \"max_length\". "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>525.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>272.630476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>539.894336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>36.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>288.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4053.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_size\n",
              "count     525.000000\n",
              "mean      272.630476\n",
              "std       539.894336\n",
              "min         1.000000\n",
              "25%         4.000000\n",
              "50%        36.000000\n",
              "75%       288.000000\n",
              "max      4053.000000"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l-FxwQaE7vz"
      },
      "source": [
        "seq_size = 228\n",
        "category_lst = [folder for folder in os.listdir('/content/text/') if not folder.endswith(\".txt\")]\n",
        "\n",
        "encode_lst = []\n",
        "for label, folder_name in enumerate(category_lst):\n",
        "    directory = '/content/text/' + folder_name + \"/\"\n",
        "    # print(directory)\n",
        "    for filename in os.listdir(directory):\n",
        "\n",
        "        txt = open(directory + filename).read().replace(\"\\u3000\", \"\").split(\"\\n\")[2:]\n",
        "        txt = \" \".join(txt) \n",
        "        encode = tokenizer(txt, max_length=seq_size, padding='max_length', truncation=True)\n",
        "        encode['labels'] = label\n",
        "        encode = { key: torch.tensor(value) for key, value in encode.items() }\n",
        "        encode_lst.append(encode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ-HdHvTg0c8",
        "outputId": "7a51921c-8a3b-46b3-8b8f-ab813c3f03df"
      },
      "source": [
        "encode_lst[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " 'input_ids': tensor([    2,   319, 28444, 29065, 28469,  4401,     5, 19445, 23141, 28520,\n",
              "          6774,   590,    36, 25312,    23, 17836, 28687,  1108,     7,  3661,\n",
              "          1317,    14,   656,   679, 30657,  9317, 29760,  9398,  9594,  4410,\n",
              "         28487,    13,    15,    10, 19445,  1575,    14,  5648,    81,    18,\n",
              "          4035, 28472,  4572, 28472, 28534,   992,     5,  3387,   834, 24040,\n",
              "         28520, 14266,   590,    36, 25312,    23, 17836, 28687,  1108,     5,\n",
              "          3661,  1317,    14,   127,    37,  8660,     7,   580,    26,    62,\n",
              "             8,  2442,   125,     9,    36, 17836, 28687,  4820,    38,     8,\n",
              "         26680,   691,    14,   626,   648,  1101, 20734,    15,     6, 16278,\n",
              "           640,    14,   101,   640,    40,    48,   143,    76,   640,     7,\n",
              "          7278,    26,    20,     6,  2216,  1317,    12,    36, 16017, 25567,\n",
              "            38,    13,    26,    20,    16,    21,    10,   972,    11,  3465,\n",
              "            15,    10,     8, 16278,    72,     5,  3296,     3]),\n",
              " 'labels': tensor(0),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "PbLGqZQ50aRt",
        "outputId": "ffc8b7a0-21ca-4f42-9c1c-9a0234f97e29"
      },
      "source": [
        "# let's see a sentence of data\n",
        "\"\".join(tokenizer.convert_ids_to_tokens(encode_lst[0]['input_ids'])).replace('##', \"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS]手のひらサイズの球体ハンディクリーナー「オーブ(ORB)」に上位モデルが登場!【売れ筋チェック】コロッとした球体デザインが印象的なブラック・アンド・デッカーのコードレスハンディクリーナー「オーブ(ORB)」の上位モデルが7月下旬に発売される。商品名は「ORB72」。吸引力が25%ほどパワーアップし、充電時間が6時間から3.5時間に短縮され、従来モデルで「イマイチ」とされていた部分を改善した。充電時の消費[SEP]'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLSgUN-kLein",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0a6baa-f382-4b8c-dabb-748acc20e3ea"
      },
      "source": [
        "train_size = int(0.9 * len(encode_lst))\n",
        "validate_size = len(encode_lst) - train_size\n",
        "train_dataset, validate_dataset = random_split(encode_lst, [train_size, validate_size])\n",
        "\n",
        "print(\"train_size:\", train_size)\n",
        "print(\"validate_size:\", validate_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_size: 6638\n",
            "validate_size: 738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rgCtM2UL1Mc"
      },
      "source": [
        "batch_size = 20\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validate_dataloader = DataLoader(validate_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMdGGkAkNuyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11dd8a1b-8480-4233-e409-d421e22827b5"
      },
      "source": [
        "%%capture\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(category_lst))\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.train() \n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGy_vOPy0pOg"
      },
      "source": [
        "`model.train() `   VS   ` model.eval()`\n",
        "\n",
        "`model.train()` tells your model that you are training the model. So effectively layers like dropout, batchnorm etc. which behave different on the train and test procedures know what is going on and hence can behave accordingly.\n",
        "\n",
        "https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WGDTpRZpGhO"
      },
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "train_loss = 0\n",
        "\n",
        "model.train() # turn on train mode\n",
        "\n",
        "for batch in train_dataloader:\n",
        "    batch_input_ids = batch['input_ids'].to(device)\n",
        "    batch_input_mask = batch['attention_mask'].to(device)\n",
        "    batch_labels = batch['labels'].to(device)\n",
        "    batch_tokens = batch['token_type_ids'].to(device)\n",
        "\n",
        "    outputs = model(input_ids = batch_input_ids, \n",
        "                    token_type_ids = batch_tokens, \n",
        "                    attention_mask = batch_input_mask, \n",
        "                    labels = batch_labels)\n",
        "    \n",
        "    loss = outputs.loss\n",
        "    loss.backward() # computes dloss/dx for every parameter x which has requires_grad=True.\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ZTxyEtJUP0"
      },
      "source": [
        "model.eval() # turn off train mode\n",
        "\n",
        "predict_lst=[]\n",
        "labels_lst = []\n",
        "\n",
        "for batch in validate_dataloader:\n",
        "    batch_input_ids = batch['input_ids'].to(device)\n",
        "    batch_input_mask = batch['attention_mask'].to(device)\n",
        "    batch_labels = batch['labels'].to(device)\n",
        "    batch_tokens = batch['token_type_ids'].to(device)\n",
        "    \n",
        "    with torch.no_grad():   \n",
        "        preds = model(batch_input_ids, token_type_ids=None, attention_mask=batch_input_mask)\n",
        "        predict_lst.append(preds)\n",
        "        labels_lst.append(batch['labels'])        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auc5DSON17g9"
      },
      "source": [
        "there are 738 articles for validation and the first 5 examples are shown below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ8dK1E3Vb-Q",
        "outputId": "29416581-4300-43ea-9b5e-ea88ab937f04"
      },
      "source": [
        "# there are 738 articles for validation\n",
        "label_lst_numpy = np.concatenate( [label_batch.cpu().numpy() for label_batch in labels_lst] )\n",
        "print(len(label_lst_numpy))\n",
        "label_lst_numpy[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "738\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 6, 2, 6, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFVTT_g6SfI_",
        "outputId": "579e3756-9857-4e7a-83b8-e99174ee7517"
      },
      "source": [
        "predict_lst_numpy = np.concatenate( [output_batch.logits.argmax(-1).cpu().numpy() for output_batch in predict_lst])\n",
        "print(len(predict_lst_numpy))\n",
        "predict_lst_numpy[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "738\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 2, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPFCGJX1bb9S"
      },
      "source": [
        "acc_df = pd.DataFrame(label_lst_numpy, columns=['label'])\n",
        "acc_df['predict'] = predict_lst_numpy\n",
        "acc_df['check'] = acc_df['label'] == acc_df['predict']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK6CoURScKal",
        "outputId": "628e81aa-68d1-4941-d03d-643bd471e323"
      },
      "source": [
        "true = acc_df[acc_df['check'] == True].shape[0]\n",
        "false = acc_df[acc_df['check'] == False].shape[0]\n",
        "all = acc_df.shape[0]\n",
        "\n",
        "print(true/all)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9173441734417345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-WyuNnu2-fM"
      },
      "source": [
        "Ref:\n",
        "1. BERTによる自然言語処理入門: Transformersを使った実践プログラミング\n",
        "2. https://gist.github.com/jshirius/34624297b834ad8192c58e9b7ab636b5#file-huggingface-transformers-bert-ipynb"
      ]
    }
  ]
}